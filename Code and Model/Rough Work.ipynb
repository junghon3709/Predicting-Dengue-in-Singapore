{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/yipjh/anaconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as pl\n",
    "import io \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please load your own path here\n",
    "combined_df=pd.read_csv(r'/Users/yipjh/Desktop/Projects/Predicting-Dengue-in-Singapore/Data/post-processed/combined_data_030120.csv')\n",
    "dengue_df=pd.read_csv(r'/Users/yipjh/Desktop/Projects/Predicting-Dengue-in-Singapore/Data/post-processed/dengue_271219.csv')\n",
    "pop_df=pd.read_csv(r'/Users/yipjh/Desktop/Projects/Predicting-Dengue-in-Singapore/Data/post-processed/population-sg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dict={}\n",
    "for i, j in pop_df.iterrows():\n",
    "    pop_dict.update({j[0]:int(j[1].replace(',',''))})\n",
    "\n",
    "pop_df['population']=pop_dict.values()\n",
    "\n",
    "oo=pd.date_range('1/2/2000', periods=7273)\n",
    "date_list=oo.to_pydatetime().tolist()\n",
    "\n",
    "op=dengue_df['Unnamed: 0']\n",
    "def foo(st):\n",
    " y=st.split('-')\n",
    " return datetime.datetime(int(y[0]), int(y[1]), int(y[2]))\n",
    "\n",
    "dt_list=list(map(foo, op))\n",
    "oo=oo.to_pydatetime().tolist()\n",
    "combined_df.index=oo\n",
    "\n",
    "combined_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "dengue_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "dengue_df.index=dt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get rid of duplicates in the dengue dataset\n",
    "def rid_duplicates(df):\n",
    "    return df.loc[~df.index.duplicated(keep='first')]\n",
    "\n",
    "trancated_dengue=rid_duplicates(dengue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to normalise the data first\n",
    "def normaliser(df, *args):\n",
    "    _=copy.copy(df)\n",
    "    for i in args:\n",
    "        ran=_[i].max()-_[i].min()\n",
    "        std=_[i].std()\n",
    "        ave=_[i].mean()\n",
    "        _[i]=(_[i]-ave)/std\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trancated_dengue=normaliser(trancated_dengue, 'dengue')\n",
    "combined_df=normaliser(combined_df, 'rain_mean', 'temp_mean')\n",
    "pop_df=normaliser(pop_df, 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_dataframe(date, x, iu, *args, **kwargs):\n",
    "    idx=date_list.index(date)\n",
    "    u=pd.DataFrame()\n",
    "    if idx-x-iu>0:\n",
    "        for i, text in zip(args, kwargs.values()):\n",
    "            o=i[idx-x-iu:idx-iu][text]\n",
    "            u[text]=o\n",
    "        return u, date\n",
    "    else:\n",
    "        return u, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df=pd.DataFrame(combined_df['rain_mean'])\n",
    "temperature_df=pd.DataFrame(combined_df['temp_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters of our inputs\n",
    "`DATA_WINDOW` refers to the number of weeks of data considered when making the prediction of dengue cases.\n",
    "\n",
    "`LEAD_TIME` refers to how many weeks in the future we are doing our dengue prediction.\n",
    "\n",
    "`MAX_EXTRACT` and `LCD` will be dealt with below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_WINDOW=16 #should be even\n",
    "LEAD_TIME=8\n",
    "MAX_EXTRACT=20 # rainfall window\n",
    "LCD=6 #should divide DATA_WINDOW or 7, increase to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b8cc910844ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrancated_dengue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdate_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdf_pushback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpull_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_WINDOW\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEAD_TIME\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrainfall_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rain_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pushback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_df=pd.DataFrame()\n",
    "tp_df=pd.DataFrame()\n",
    "\n",
    "for date in trancated_dengue.index:\n",
    "    if date in date_list:\n",
    "        df_pushback, dat=pull_dataframe(date, DATA_WINDOW*7, LEAD_TIME*7, rainfall_df, temperature_df, label1='rain_mean', label2='temp_mean')\n",
    "    if len(df_pushback)!=0:\n",
    "        rf_df[dat]=df_pushback['rain_mean'].values\n",
    "        tp_df[dat]=df_pushback['temp_mean'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, to do prediction on the dengue cases in 2000-06-19, rainfall and temperature data from 8-24 weeks back are used. This gives us a 112 days of rainfall and temperature data, which are indexed 0-111 down the columns in both the `rf_df` and `tp_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Reduction\n",
    "\n",
    "The rainfall daily and temperature data are noisy. As explained in the medium article, we will be focusing on the maximum $n$ days, as well as other metrics (such as mean and std) to reduce the noise.\n",
    "\n",
    "`MAX_EXTRACT`=$n$. Takes out the maximum $n$ rainfall/temperature data down each column.\n",
    "\n",
    "`LCD`=$d$. Takes an interval of $d$ days from the `DATA_WINDOW*7=112` days and averages it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_max(df, n , label):\n",
    "  size=np.argsort(df.values, axis=0)[-n:].T.shape\n",
    "  ref=np.argsort(df.values, axis=0)[-n:]\n",
    "  # rainfall_values=rf_df.values.T\n",
    "  maximum_values=np.zeros((size[0], n))\n",
    "\n",
    "  for i in range(size[0]):\n",
    "    for j in range(n):\n",
    "      pos=ref.T[i][j]\n",
    "      val=df.values[pos][i]\n",
    "      maximum_values[i, j]=val\n",
    "\n",
    "  columns_list=[]\n",
    "  for i in range(1, n+1):\n",
    "    columns_list.append(label+str(i))\n",
    "\n",
    "  maximum_df=pd.DataFrame(maximum_values, columns=columns_list)\n",
    "  return maximum_df\n",
    "\n",
    "maximum_rainfall_df=extract_max(rf_df, MAX_EXTRACT, 'rainfallmax')\n",
    "maximum_temperature_df=extract_max(tp_df, MAX_EXTRACT, 'temperaturemax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seven_day_mean(n, d, **kwargs): # where d should be a divisor of n, chooose d smaller for more 'rugged' data\n",
    "    a=pd.DataFrame()\n",
    "    for j, df in zip(kwargs.keys(), kwargs.values()):\n",
    "        for i in range(0, n , d):\n",
    "            label=str(j)+str( i)\n",
    "            a[label]=df[i:i+d].mean(axis=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seven_day_mean=seven_day_mean(DATA_WINDOW*7, LCD, mean_rain=rf_df, mean_temp=tp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rainfall/temp metrics such as max, min, std, med\n",
    "mean_df=pd.DataFrame()\n",
    "\n",
    "mean_df['temp_mean']=list(tp_df.mean(axis=0))\n",
    "mean_df['temp_std']=list(tp_df.std(axis=0))\n",
    "mean_df['temp_min']=list(tp_df.min(axis=0))\n",
    "mean_df['temp_max']=list(tp_df.max(axis=0))\n",
    "mean_df['temp_med']=list(tp_df.median(axis=0))\n",
    "\n",
    "mean_df['rain_mean']=list(rf_df.mean(axis=0))\n",
    "mean_df['rain_std']=list(rf_df.std(axis=0))\n",
    "mean_df['rain_min']=list(rf_df.min(axis=0))\n",
    "mean_df['rain_max']=list(rf_df.max(axis=0))\n",
    "mean_df['rain_med']=list(rf_df.median(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df=mean_df.merge(maximum_rainfall_df, left_index=True, right_index=True)\n",
    "mean_df=mean_df.merge(maximum_temperature_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=df_seven_day_mean.index\n",
    "df_seven_day_mean.reset_index(drop=True, inplace=True)\n",
    "mean_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(a, b):\n",
    "    indexes=a.index\n",
    "    a.reset_index(drop=True, inplace=True)\n",
    "    b.reset_index(drop=True, inplace=True)\n",
    "    for col in b.columns:\n",
    "        a[col]=b[col]\n",
    "    a.index=indexes\n",
    "    return a\n",
    "\n",
    "mean_df=merge(mean_df, df_seven_day_mean)\n",
    "mean_df.index=indexes\n",
    "combined_Data=mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_append=trancated_dengue[trancated_dengue.index>=combined_Data.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Data['dengue_actual']=dengue_append['dengue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding population data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df=pop_df[pop_df['year']>=2000]\n",
    "a=[]\n",
    "for i in combined_Data.index:\n",
    "    a.append(pop_dict[i.year])\n",
    "\n",
    "combined_Data['population']=a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding past dengue data\n",
    "\n",
    "This section adds past dengue data prior to the actual date which we wish to predict. For instance, if we wish to predict dengue cases in week $24$ with a lead time of $8$, dengue cases from week $1-16$ are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(df, data_window, lead_time):\n",
    "  dengue_shift=pd.DataFrame()\n",
    "  for i in range(data_window+lead_time+1):\n",
    "      dengue_shift[-i]=list(df['dengue'].shift(i))\n",
    "  for i in range(LEAD_TIME+1):\n",
    "    dengue_shift.drop([-i], axis=1, inplace=True)\n",
    "  dengue_shift=dengue_shift.dropna()\n",
    "  return dengue_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_shift=shift(trancated_dengue, DATA_WINDOW, LEAD_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here, -9 indicates the most recent data and -24 incidcates the most outdated data, ie 15 weeks before week -9. \n",
    "# The week which we wish to predict is considered week 0 which corresponds to a lead time of 8.\n",
    "dengue_shift.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This averages specific columns from the `dengue_shift` dataframe. `ave2` takes in the 2 most recent data entries and averages them. (ie. from -9 to -10). `ave4` takes in the 4 most recent entries and does the same. (ie. from -9 to -13). This tries to reduce noise in the dengue dataset without completely getting rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_last_n_cols(df, *args):\n",
    "  df_average=pd.DataFrame()\n",
    "  c= copy.copy(df)\n",
    "  for n in args:\n",
    "    f=c[c.columns[0:n]]\n",
    "    average_n=f.mean(axis=1)\n",
    "    label='ave' + str(n)\n",
    "    df_average[label]=average_n\n",
    "  return df_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_intevals=list(np.arange(2, DATA_WINDOW+2, 2))\n",
    "dengue_average=average_last_n_cols(dengue_shift, *ave_intevals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_average.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_process=merge(dengue_shift, dengue_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dengue trends\n",
    "\n",
    "`trend` is simply: (last week-first week)/DATA_WINDOW, and in our case: `(week[-9]-week[-24])/DATA_WINDOW)`.\n",
    "\n",
    "`strong_trend` takes: (ave2-ave(DATA_WINDOW))/DATA_WINDOW, and in our case: `(ave2-ave16)/DATA_WINDOW)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_trend(df, lead_time, data_window):\n",
    "  dengue_trend=pd.DataFrame()\n",
    "  dengue_trend['trend']=(df[-data_window-lead_time]-dengue_shift[-lead_time-1])/data_window\n",
    "  return dengue_trend\n",
    "\n",
    "def df_str_trend(df, weak, strong, data_window):\n",
    "  strong_trend=pd.DataFrame()\n",
    "  weak_label='ave'+str(weak)\n",
    "  strong_label='ave'+str(strong)\n",
    "  strong_trend['strong_trend']=(df[strong_label]-dengue_shift[weak_label])/data_window\n",
    "  return strong_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_trend=df_trend(dengue_process, LEAD_TIME, DATA_WINDOW)\n",
    "strong_trend=df_str_trend(dengue_process, 2, DATA_WINDOW, DATA_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_process=merge(dengue_process, dengue_trend)\n",
    "dengue_process=merge(dengue_process, strong_trend)\n",
    "dengue_process['dengue_std']=list(dengue_shift.std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_process_norm=normaliser(dengue_process, 'trend', 'strong_trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Data=merge(dengue_process_norm, combined_Data)\n",
    "combined_Data.index=indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding year month data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Data['year']=combined_Data.index.year\n",
    "combined_Data['month']=combined_Data.index.month\n",
    "combined_Data['trend']=list(dengue_trend['trend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Data=normaliser(combined_Data, 'year','month', 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dengue_actual_to_back(df):\n",
    " a=pd.DataFrame(df['dengue_actual'])\n",
    " df.drop(['dengue_actual'], axis=1, inplace=True)\n",
    " df['dengue_actual']=a\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised=move_dengue_actual_to_back(combined_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "Into X (features) and y (labels) and into training the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_normalised.drop('dengue_actual', axis=1)\n",
    "Y=pd.DataFrame(df_normalised['dengue_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_loss(a,b):\n",
    "    return np.mean((a-b)**2)\n",
    "\n",
    "def baseline(df):\n",
    "  a=df[-LEAD_TIME-1]\n",
    "  b=df['dengue_actual']\n",
    "  return euclid_loss(a,b), list(a), list(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=0.90\n",
    "train_size=int(len(X)*ratio)\n",
    "test_size=int(len(X)*(1-ratio));\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline prediction\n",
    "Involves shifting the graph `-LEAD_TIME` units and simply making predictions out of this shifted graph. This is the loss we will attempt to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, pred, actual=baseline(df_normalised[-test_size:]); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(actual, label= 'Actual')\n",
    "plt.plot(pred, label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[:train_size].values\n",
    "X_test=X[train_size+1:len(X)].values\n",
    "y_train=Y[:train_size].values\n",
    "y_test=Y[train_size+1:len(Y)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "Here we analyse correlation. We find that maximum rainfall is negatively correlated with dengue cases, as surprisingly, it could signal instances of flushing. Temperature is postiviely correlated with dengue. The bright yellow region in the top right signals that past weeks of dengue data is strongly correlated with the dengue cases in the week we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised.corr().tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(5, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.imshow(df_normalised.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Flatten, Activation ,GRU\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "# LeakyRelu=keras.layers.LeakyReLU(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(1, X_train.shape[2]),return_sequences=True))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(98))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(64, activation=LeakyRelu, return_sequences=True))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1, activation=tf.nn.elu))\n",
    "Adam=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.99, beta_2=0.999, amsgrad=True, decay=0.0001)\n",
    "SGD = tf.keras.optimizers.SGD(lr=0.003, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=SGD,\n",
    "              loss='mean_squared_error',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, \n",
    "                  y_train, \n",
    "                  epochs=60,\n",
    "                  batch_size=64, \n",
    "#                   callbacks = [callback],\n",
    "                  validation_data=(X_test, y_test), \n",
    "                  verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing our losses\n",
    "Note that the results of this section may differ for some people. We have managed to get `val-loss` down to about 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(history.history['loss']+[0.1639], label='Training loss')\n",
    "plt.plot(history.history['val_loss']+[0.1688], label='Testing loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('epic-dengue-model070120')\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "p=model.predict(X_test)\n",
    "plt.plot(y_test, label='Actual')    \n",
    "plt.plot(p, label='Model Predictions')\n",
    "plt.legend()\n",
    "# euclid_loss(y_test, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclid_loss(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "p=model.predict(X_test)\n",
    "plt.plot(y_test, label='Actual')    \n",
    "# plt.plot(p, label='Model Predictions')\n",
    "plt.legend()\n",
    "# euclid_loss(y_test, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_process[[-9,-10,-11,-12, 'ave2', 'ave4','ave16','trend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(df_normalised.corr()['dengue_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[a.index.isin(['rain_max', 'population', 'year', 'rain_mean','temp_mean', 'ave16', 'ave2', 'trend'])].sort_values(['dengue_actual'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort_values(['dengue_actual'], ascending=False).head(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort_values(['dengue_actual'], ascending=False).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a.index:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
